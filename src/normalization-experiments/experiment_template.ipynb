{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory.\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path to be able to import modules from 'lib.'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGeeI-H3NGMx"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Markdown as md\n",
    "import itertools\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from lib.memory import DSDM\n",
    "from lib.utils import cleanup, configs, inference, learning, preprocess, utils \n",
    "\n",
    "import torch\n",
    "import torchhd as thd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "# Type checking\n",
    "from typing import List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fix seed.\n",
    "utils.fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iuLthXgNKLP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parametrized cell: The variable is initialized with the dictionary read form the YAML config file.\n",
    "# If the notebook is being run on its own (i.e., without runing the run_experiment.sh script and giving a configuratin YAML as input),\n",
    "# the default experiment is run. Note: This should also be the case if the run_experiemnt.sh script is run on its wn (i.e., with a YAML)\n",
    "# as input\n",
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The notebook is not run from run_experiment.sh script.\n",
    "if config == {}: # Empty dictionary\n",
    "    # Read default YAML; the default YAML is experiment-1.yaml.\n",
    "    display(md(\"No YAML configuration file was provided. Runing default configuration: 'experiment-1.yaml' \"))\n",
    "    config = configs.Config.from_file(\"configs/experiment-1.yaml\")\n",
    "else:\n",
    "    # Initialize config from input YAML.\n",
    "    display(md(\"Runing provided YAML configuration.\"))\n",
    "    config = configs.Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(md(f\"# Experiment {config.experiment_title} results\"))\n",
    "utils.display_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = cleanup.Cleanup(config.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory/ies.\n",
    "if config.experiment_type == 'comparison':\n",
    "    memory_normalized = DSDM.DSDM(\n",
    "        address_size=config.dim,\n",
    "        ema_time_period=config.DSDM.ema_time_period,\n",
    "        learning_rate_update=config.DSDM.learning_rate_update,\n",
    "        temperature=config.DSDM.temperature,\n",
    "        normalize=True\n",
    "    )\n",
    "    memory_unnormalized = DSDM.DSDM(\n",
    "        address_size=config.dim,\n",
    "        ema_time_period=config.DSDM.ema_time_period,\n",
    "        learning_rate_update=config.DSDM.learning_rate_update,\n",
    "        temperature=config.DSDM.temperature,\n",
    "        normalize=False\n",
    "    )\n",
    "    memories = {\n",
    "        memory_normalized.get_memory_type(): memory_normalized,\n",
    "        memory_unnormalized.get_memory_type(): memory_unnormalized\n",
    "    }\n",
    "else:\n",
    "    memory = DSDM.DSDM(\n",
    "        address_size=config.dim,\n",
    "        ema_time_period=config.DSDM.ema_time_period,\n",
    "        learning_rate_update=config.DSDM.learning_rate_update,\n",
    "        temperature=config.DSDM.temperature,\n",
    "        normalize=config.DSDM.normalize\n",
    "    )\n",
    "    memories = {\n",
    "        memory.get_memory_type(): memory\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial training\n",
    "learning.online_learning_with_inference(\n",
    "    cleanup=cleanup,\n",
    "    memories=memories,\n",
    "    data_path=config.initial_training.data_path,\n",
    "    chunk_sizes=config.initial_training.chunk_sizes,\n",
    "    epochs=config.initial_training.epochs,\n",
    "    infer=False,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index to get the similarities of the tokens we keep track of.\n",
    "index = list(itertools.product(config.inference.sentences, config.inference.tracked_tokens))\n",
    "\n",
    "# Construct dataframes for keeping track of token similarities.\n",
    "initial_sims_dfs = {}\n",
    "#initial_tracked_tokens_sims_dfs = {}\n",
    "\n",
    "display(md(\"## Initial training\"))\n",
    "\n",
    "for memory_type, memory in memories.items():\n",
    "    initial_sims_dfs[memory_type] = inference.infer(\n",
    "        config.dim,\n",
    "        cleanup,\n",
    "        memory,\n",
    "        config.inference.sentences\n",
    "    )\n",
    "#     initial_tracked_tokens_sims_dfs[memory_type] = initial_sims_dfs[memory_type].loc[index]\n",
    "\n",
    "display(HTML(f'<a id=\"initial-training-extracted-concepts\"> </a>'))\n",
    "display(md(\"### Extracted concepts\"))\n",
    "utils.column_output(\n",
    "    memories=memories,\n",
    "    tables=initial_sims_dfs,\n",
    "    horizontal_output=False\n",
    ")\n",
    "#display(HTML(f'<a id=\"initial-training-tracked-tokens-similarities\"> </a>'))\n",
    "#display(md(\"### Tracked tokens similarties\"))\n",
    "#utils.column_output(\n",
    "#    memories=memories,\n",
    "#    tables=initial_tracked_tokens_sims_dfs,\n",
    "#    horizontal_output=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display(HTML(f'<a id=\"initial-training-memory-state\"> </a>'))\n",
    "#display(md(\"### Memory state\"))\n",
    "#for memory_type, memory in memories.items():\n",
    "#    display(md(f\"#### <ins>{memory_type.capitalize()}</ins>\"))\n",
    "#    concepts_df = inference.display_and_get_memory_addresses(memory, cleanup)\n",
    "#    inference.get_similarity_matrix_of_addresses_mapping_to_same_concepts(concepts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Online training.\n",
    "#sims_dfs, tracked_tokens_dfs = learning.online_learning_with_inference(\n",
    "#    cleanup=cleanup,\n",
    "#    memories=memories,\n",
    "#    data_path=config.training.data_path,\n",
    "#    chunk_sizes=config.training.chunk_sizes,\n",
    "#    epochs=config.training.epochs,\n",
    "#    infer=True,\n",
    "#    inference_sentences=config.inference.sentences,\n",
    "#    tracked_tokens=config.inference.tracked_tokens,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(md(\"## Training\"))\n",
    "#\n",
    "#display(HTML(f'<a id=\"training-extracted-concepts\"> </a>'))\n",
    "#display(md(\"### Extracted concepts\"))\n",
    "#utils.column_output(\n",
    "#    memories=memories,\n",
    "#    tables=sims_dfs,\n",
    "#    horizontal_output=False\n",
    "#)\n",
    "#display(HTML(f'<a id=\"training-tracked-tokens-similarities\"> </a>'))\n",
    "#display(md(\"### Tracked tokens similarties\"))\n",
    "#utils.column_output(\n",
    "#    memories=memories,\n",
    "#    tables=tracked_tokens_dfs,\n",
    "#    horizontal_output=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(HTML(f'<a id=\"training-memory-state\"> </a>'))\n",
    "#display(md(\"### Memory state\"))\n",
    "#for memory_type, memory in memories.items():\n",
    "#    display(md(f\"#### <ins>{memory_type.capitalize()}</ins>\"))\n",
    "#    concepts_df = inference.display_and_get_memory_addresses(memory, cleanup)\n",
    "#    inference.get_similarity_matrix_of_addresses_mapping_to_same_concepts(concepts_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
