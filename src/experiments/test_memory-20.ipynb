{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ea47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory.\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path to be able to import modules from 'lib.'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b779e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfs/home/dfichiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /nfs/home/dfichiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, Markdown as md\n",
    "import itertools\n",
    "\n",
    "from lib.memory import DSDM\n",
    "from lib.utils import cleanup, configs, inference, learning, preprocess, utils \n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import string\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "import torchhd as thd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Package options ###\n",
    "torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823ecf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utils ###\n",
    "def plot_heatmap(x: np.array, labels: np.array) -> None:\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(\n",
    "        x,\n",
    "        linewidth=0.5,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "    )\n",
    "    plt.title(f'Self-attention matrix: layer {layer}, head {head}', fontsize=15)\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def average_out_and_remove_rows(t: torch.tensor, averages_idx, remove_idx):\n",
    "    for average_idx in averages_idx:  # The nested lists can have different dimensions.\n",
    "        # Replace the attention scores of the first token with the average of the token attention scores.\n",
    "        t[min(average_idx)] = torch.mean(t[average_idx], dim=0, keepdim=True)\n",
    "    return t[~remove_idx]\n",
    "\n",
    "\n",
    "def preprocess_attention_scores(attention_scores, averages_idx, remove_idx):\n",
    "    attention_scores = average_out_and_remove_rows(attention_scores, averages_idx, remove_idx)\n",
    "    attention_scores = attention_scores.transpose(0, 1)\n",
    "    attention_scores = average_out_and_remove_rows(attention_scores, averages_idx, remove_idx)\n",
    "    return attention_scores.transpose(0, 1)\n",
    "        \n",
    "    \n",
    "\n",
    "def backward_pass(G, current_node, left_edge, right_edge, sequence, mean):\n",
    "    in_nodes = np.array([edge[0] for edge in list(G.in_edges(current_node))])\n",
    "    in_nodes = in_nodes[(in_nodes > left_edge) & (in_nodes < current_node)]\n",
    "    for node in in_nodes:\n",
    "        sequence[node] = 1\n",
    "        sequences.append(sequence)\n",
    "        mean += G[node][current_node]['weight']\n",
    "        means.append(round(mean / (sum(sequence) - 1), 2))\n",
    "        backward_pass(G, node, left_edge, node, sequence.copy(), mean)\n",
    "        forward_pass(G, node, left_edge, current_node, sequence.copy(), mean)\n",
    "        \n",
    "    return\n",
    "    \n",
    "    \n",
    "def forward_pass(G, current_node, left_edge, right_edge, sequence, mean):\n",
    "    out_nodes = np.array([edge[1] for edge in list(G.out_edges(current_node))])\n",
    "    out_nodes = out_nodes[(out_nodes > current_node) & (out_nodes < right_edge)]\n",
    "    for node in out_nodes:\n",
    "        sequence[node] = 1\n",
    "        mean += G[current_node][node]['weight']\n",
    "        sequences.append(sequence)\n",
    "        means.append(round(mean / (sum(sequence) - 1), 2))\n",
    "        backward_pass(G, node, current_node, node, sequence.copy(), mean)\n",
    "        forward_pass(G, node, node, right_edge, sequence.copy(), mean)\n",
    "            \n",
    "    return\n",
    "    \n",
    "\n",
    "def construct_sequences(G: nx.DiGraph, n_tokens):\n",
    "    for node in G.nodes():\n",
    "        sequence = np.zeros(n_tokens)\n",
    "        mean = 0\n",
    "        sequence[node] = 1\n",
    "        #sequences.append(sequence) # Do not allow for 1-token sequences.\n",
    "        forward_pass(G, node, node, n_tokens, sequence.copy(), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7b553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/nfs/data/projects/daniela/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2015f67259434c7ea082612f70309c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Wikipedia dataset.\n",
    "# TODO: Split between server and local.\n",
    "#wiki_dataset = datasets.load_dataset(\"wikipedia\", \"20220301.en\")['train']\n",
    "wiki_dataset = datasets.load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.en\",\n",
    "    cache_dir=\"/nfs/data/projects/daniela\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d20065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct train set (texts) and inference set (sentences; in and out of train set text).\n",
    "train_size = 5000\n",
    "test_size = 20\n",
    "\n",
    "# Text indeces.\n",
    "train_idx = np.random.randint(0, len(wiki_dataset), size=train_size)\n",
    "#train_idx = np.append(np.append(np.append(train_idx[0], train_idx[0]), train_idx[0]), train_idx[0]) \n",
    "\n",
    "\n",
    "# Text indeces from which we extract sentences.\n",
    "intest_idx = np.random.choice(train_idx, test_size)\n",
    "outtest_idx = np.random.choice(np.setdiff1d(np.arange(len(wiki_dataset)), train_idx), test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b4da7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sentences_in = []\n",
    "inference_sentences_out = []\n",
    "\n",
    "for idx_in, idx_out in zip(intest_idx, outtest_idx):\n",
    "    # Get sentences.\n",
    "    sentences_in = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_in)]['text'])\n",
    "    sentences_out = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_out)]['text'])\n",
    "    \n",
    "    # Get sentence index.\n",
    "    sentence_idx_in = np.random.randint(0, len(sentences_in), size=1).item()\n",
    "    sentence_idx_out = np.random.randint(0, len(sentences_out), size=1).item()\n",
    "\n",
    "    # Append sentence to list.\n",
    "    inference_sentences_in.append(sentences_in[sentence_idx_in])\n",
    "    inference_sentences_out.append(sentences_out[sentence_idx_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea907c4",
   "metadata": {},
   "source": [
    "Concepts: \n",
    "- university\n",
    "- center\n",
    "- culture\n",
    "- exam\n",
    "- day and days\n",
    "- floor\n",
    "- stage\n",
    "- loan\n",
    "- record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f51d05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:  Brave was later named as one of the School Library Journal Top 10 Graphic Novels of 2017.\n",
      " \n",
      "Sentence 2:  By the late 19th century, the building was in an extremely dilapidated state and under threat of demolition, before being extensively restored by the socialite, Lady Meux and her husband, in 1889.\n",
      " \n",
      "Sentence 3:  Black was a right-handed batsman who bowled right-arm medium.\n",
      " \n",
      "Sentence 4:  The Wilhelm Schmid Museum was the residence of the artist (1892–1971) and today contains a collection of his works.\n",
      " \n",
      "Sentence 5:  Between 1908 and 1910 he was at the university surgical clinic in Greifswald under Erwin Payr (1871–1947), then went to Königsberg to work with Payr and Paul Leopold Friedrich (1864–1916).\n",
      " \n",
      "Sentence 6:  Daniel Finch may refer to:\n",
      "\n",
      "Daniel Finch, 2nd Earl of Nottingham and 7th Earl of Winchilsea (1647–1730)\n",
      "Daniel Finch, 8th Earl of Winchilsea (1689–1769), British politician\n",
      " \n",
      "Sentence 7:  Vinogradi is a village in the municipality of Sandanski, in Blagoevgrad Province, Bulgaria.\n",
      " \n",
      "Sentence 8:  Winners and nominees\n",
      "Winners are listed first and highlighted in bold.\n",
      " \n",
      "Sentence 9:  This meant the removal of a river lock entrance and an access channel to the Great Float, in order to reconstruct the remaining facilities.\n",
      " \n",
      "Sentence 10:  Talamasca can mean:\n",
      " Talamasca (order), a fictional secret society from Anne Rice's books\n",
      " Talamasca (group), a musical group whose name comes from the above fictional books\n",
      " \n",
      "Sentence 11:  In 1935 he was appointed inspector of cavalry in Libya, and from 1937 to 1940 he commanded the Regiment \"Nizza Cavalleria\" (1st).\n",
      " \n",
      "Sentence 12:  In larger quantities, an extract of the bark is a powerful, cardiac poison, rapidly causing shortness of breath, convulsions and cardiac arrest.\n",
      " \n",
      "Sentence 13:  References\n",
      "Soccerballworld retrieved dec.2017\n",
      "\n",
      "Sports equipment\n",
      "Valves\n",
      " \n",
      "Sentence 14:  References\n",
      "\n",
      "Logic puzzles\n",
      " \n",
      "Sentence 15:  Jaljalat (Arabic: thunder) is an armed Sunni Islamist group operating in the Gaza Strip taking inspiration from al-Qaeda.\n",
      " \n",
      "Sentence 16:  His works have been published in art periodicals, such as American Art Collector, Fine Art Connoisseur, The Artist, Professional Artist, The Huffington Post and Poets and Artists magazine, where he received the cover for the Nov 2009 Issue.\n",
      " \n",
      "Sentence 17:  It is endemic to Venezuela.\n",
      " \n",
      "Sentence 18:  The movie was directed by C. P. Dixit and was released in 1989.\n",
      " \n",
      "Sentence 19:  In 2014, Bleck left Interscope following reorganization of the company.\n",
      " \n",
      "Sentence 20:  It is found in Argentina, Bolivia, Brazil, Guyana, Peru, and Venezuela.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(inference_sentences_in):\n",
    "    print(f\"Sentence {idx + 1}: \", sentence)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c37031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0:  He played college football at Alabama and UCF, and was drafted by the Giants in the third round of the 2021 NFL Draft.\n",
      " \n",
      "Sentence 1:  Billings was born at Redcliffe manor on Beech Island, South Carolina, a plantation built by his great-grandfather the senator (famed for the saying \"Cotton is king\").\n",
      " \n",
      "Sentence 2:  References\n",
      "\n",
      "External links \n",
      " \n",
      "\n",
      "1978 births\n",
      "Living people\n",
      "Polish footballers\n",
      "Lech Poznań players\n",
      "Warta Poznań players\n",
      "Sportspeople from Poznań\n",
      "Association football midfielders\n",
      " \n",
      "Sentence 3:  Salchow  may refer to:\n",
      "\n",
      " Ulrich Salchow (1877–1949), Swedish figure skater\n",
      " Salchow jump, a figure skating jump named after him\n",
      " \n",
      "Sentence 4:  The name is in part derived from the town where they were first observed, Gabela.\n",
      " \n",
      "Sentence 5:  Jacob Gaukel Stroh (25September 184823May 1935) was a local historian of Waterloo County, Ontario.\n",
      " \n",
      "Sentence 6:  References\n",
      "\n",
      "Further reading\n",
      "\n",
      "External links\n",
      "\n",
      " \n",
      "\n",
      "Oecophorinae\n",
      "Moths described in 1907\n",
      " \n",
      "Sentence 7:  Some bebop tunes use a dominant chord as the tonic chord and also use dominant chords for the chords that would typically be minor chords in a Classical piece or a swing arrangement.\n",
      " \n",
      "Sentence 8:  History\n",
      "Construction of the plant began in 1977 and completed in 1980.\n",
      " \n",
      "Sentence 9:  External links\n",
      " http://tenncomgroup.com/aboutus.php\n",
      "\n",
      "1976 births\n",
      "Living people\n",
      "People from Wildwood, Florida\n",
      "Players of American football from Florida\n",
      "American football wide receivers\n",
      "Itawamba Indians football players\n",
      "Lambuth Eagles football players\n",
      "New York Giants players\n",
      "West Georgia Wolves football players\n",
      " \n",
      "Sentence 10:  It divided the work into two areas: \"agency action\" led by Ron Nicol and \"policy implementation\" led by Ado Machida.\n",
      " \n",
      "Sentence 11:  Locke Station is located along U.S. Route 278 and Mississippi Highway 6, east of Marks.\n",
      " \n",
      "Sentence 12:  It would have focused on Batman's relationship with the Justice League, particularly Superman, and the main villains would have been Lex Luthor and OMAC.\n",
      " \n",
      "Sentence 13:  It is found in Uzbekistan.\n",
      " \n",
      "Sentence 14:  It was first surveyed in 1936 by the British Graham Land Expedition (BGLE) under Rymill and resurveyed in 1948 by the Falkland Islands Dependencies Survey (FIDS) who named it after the submarine Nautilus in Jules Verne's Twenty Thousand Leagues Under The Sea.\n",
      " \n",
      "Sentence 15:  Critical reception\n",
      "The episode was received warmly by most television critics.\n",
      " \n",
      "Sentence 16:  The road provides parking lot access to Rivergate Mall, one of the Nashville area’s premier shopping centers.\n",
      " \n",
      "Sentence 17:  In September 1851, the town organized Bone Burying Day, to inter the remains of bones that had been discovered from the battles at that location.\n",
      " \n",
      "Sentence 18:  Ferrand became a prominent public intellectual and participated in many French political and societal debates.\n",
      " \n",
      "Sentence 19:  Gallery\n",
      "\n",
      "See also\n",
      "List of sausages\n",
      "\n",
      "References\n",
      "\n",
      "Spanish sausages\n",
      "Catalan cuisine\n",
      "Fermented sausages\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(inference_sentences_out):\n",
    "    print(f\"Sentence {idx}: \", sentence)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d40771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcb4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
