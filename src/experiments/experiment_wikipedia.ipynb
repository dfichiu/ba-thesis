{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window n-gram method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory.\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path to be able to import modules from 'lib.'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dGeeI-H3NGMx"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from IPython.display import HTML, Markdown as md\n",
    "import itertools\n",
    "\n",
    "from lib.memory import DSDM\n",
    "from lib.utils import cleanup, configs, inference, learning, preprocess, utils \n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchhd as thd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "# Type checking\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/nfs/data/projects/daniela/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52a25d37c8044b098ed4b573c0cfe50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Wikipedia dataset.\n",
    "# TODO: Split between server and local.\n",
    "#wiki_dataset = datasets.load_dataset(\"wikipedia\", \"20220301.en\")['train']\n",
    "wiki_dataset = datasets.load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.en\",\n",
    "    cache_dir=\"/nfs/data/projects/daniela\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Using seed: 41"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seed.\n",
    "utils.fix_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6iuLthXgNKLP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set DSDM hyperparameters.\n",
    "address_size = 1000\n",
    "\n",
    "ema_time_period = 5000\n",
    "learning_rate_update = 0.8\n",
    "\n",
    "temperature = 0.5\n",
    "\n",
    "normalize = False\n",
    "\n",
    "chunk_sizes = [3]\n",
    "\n",
    "# Pruning\n",
    "prune_mode = None\n",
    "max_size_address_space = 4000\n",
    "\n",
    "\n",
    "# Pruning: Remove dups\n",
    "remove_dups = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = cleanup.Cleanup(address_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory.\n",
    "memory = DSDM.DSDM(\n",
    "    address_size=address_size,\n",
    "    ema_time_period=ema_time_period,\n",
    "    learning_rate_update=learning_rate_update,\n",
    "    temperature=temperature,\n",
    "    normalize=normalize,\n",
    "    prune_mode=prune_mode,\n",
    "    max_size_address_space=max_size_address_space\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct train set (texts) and inference set (sentences; in and out of train set text).\n",
    "train_size = 250\n",
    "test_size = 10\n",
    "\n",
    "# Text indeces\n",
    "train_idx = np.random.randint(0, len(wiki_dataset) - 100, size=train_size)\n",
    "# Generate and append train articles present in all experiments.\n",
    "intest_idx = np.random.randint(len(wiki_dataset) - 100, len(wiki_dataset), size=20)\n",
    "_set = list(set(intest_idx))\n",
    "intest_idx = np.array(_set)[: len(_set) // 2]\n",
    "#outtest_idx = np.array(_set)[len(_set) // 2 :]\n",
    "train_idx = np.append(train_idx, intest_idx)\n",
    "\n",
    "# Text indeces from which we extract sentences.\n",
    "#intest_idx = np.random.choice(train_idx, test_size)\n",
    "#outtest_idx = np.random.choice(np.setdiff1d(np.arange(len(wiki_dataset)), train_idx), test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_sentences_in = []\n",
    "# inference_sentences_out = []\n",
    "\n",
    "# for idx_in, idx_out in zip(intest_idx, outtest_idx):\n",
    "#     # Get sentences.\n",
    "#     sentences_in = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_in)]['text'])\n",
    "#     sentences_out = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_out)]['text'])\n",
    "    \n",
    "#     # Get sentence index.\n",
    "#     sentence_idx_in = int(\n",
    "#         np.random.randint(\n",
    "#             0,\n",
    "#             len(sentences_in),\n",
    "#             size=1\n",
    "#         ).item()\n",
    "#     )\n",
    "#     sentence_idx_out = int(\n",
    "#         np.random.randint(\n",
    "#             0,\n",
    "#             len(sentences_out),\n",
    "#             size=1\n",
    "#         ).item()\n",
    "#     )\n",
    "\n",
    "#     # Append sentence to list.\n",
    "#     inference_sentences_in.append(sentences_in[sentence_idx_in])\n",
    "#     inference_sentences_out.append(sentences_out[sentence_idx_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove duplicates ###\n",
    "\n",
    "dups_found = 0\n",
    "\n",
    "def remove_duplicates(memory):\n",
    "    global dups_found\n",
    "    global_keep_mask = torch.tensor([True] * len(memory.addresses)).to(device)\n",
    "    \n",
    "    for idx, address in enumerate(memory.addresses):\n",
    "        if global_keep_mask[idx].item():\n",
    "            cos = torch.nn.CosineSimilarity()\n",
    "            keep_mask = cos(memory.addresses, address) < 0.8\n",
    "            # Keep current address\n",
    "            keep_mask[idx] = True\n",
    "            global_keep_mask &= keep_mask\n",
    "\n",
    "    if global_keep_mask.sum().item() > 0:\n",
    "        dups_found += len(global_keep_mask) - global_keep_mask.sum().item()\n",
    "        # Remove similar addresses\n",
    "        memory.addresses = memory.addresses[global_keep_mask]\n",
    "        # Remove bins & chunk scores\n",
    "        memory.scores = memory.scores[global_keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 259/259 [01:56<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in tqdm(train_idx):\n",
    "    text = wiki_dataset[int(i)]['text']\n",
    "    \n",
    "    # Preprocess data. \n",
    "    sentences_tokens = preprocess.preprocess_text(text)\n",
    "    for sentence_tokens in sentences_tokens:\n",
    "        # Generate atomic HVs for unknown tokens.\n",
    "        learning.generate_atomic_HVs_from_tokens_and_add_them_to_cleanup(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            sentence_tokens\n",
    "        )\n",
    "        \n",
    "        # Learning: Construct the chunks of each sentence and save them to memory.\n",
    "        learning.generate_chunk_representations_and_save_them_to_memory(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            memory,\n",
    "            sentence_tokens,\n",
    "            chunk_sizes=chunk_sizes\n",
    "        )\n",
    "    if remove_dups:\n",
    "        remove_duplicates(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_sentences_in = ['Dagored', 'is an Italian', 'record labels', 'based in Firenze', 'formed', 'in 1998.'] 250, 0.05 temperature\n",
    "# 'record labels' also caught by transformer attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_partition(input_partition, output_partition):\n",
    "#     # Note: What if a sentence contains the same word multiple times? This is why using 'set' is  bad idea!\n",
    "#     set_query = set(preprocess.remove_stopwords(tokens)[0]) \n",
    "#     set_content = inference.get_most_similar_HVs(sentence_sims_df, delta_threshold=0.1)\n",
    "\n",
    "#     set_input = set(input_partition)\n",
    "#     set_output = set(output_partition)\n",
    "    \n",
    "#     score = len(set_input.intersection(set_output)) / len(set_input)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def divide_and_conquer(token_partitions: typing.List[typing.List[str]]):\n",
    "#     retrieve_mode = \"pooling\"\n",
    "    \n",
    "#     for tp in token_partitions:\n",
    "#         retrieved_content = inference.infer(\n",
    "#             memory.address_size,\n",
    "#             cleanup,\n",
    "#             memory,\n",
    "#             [tp],\n",
    "#             retrieve_mode=retrieve_mode\n",
    "#         )\n",
    "#         output_tokens = inference.get_most_similar_HVs(\n",
    "#             inference.get_similarities_to_atomic_set(\n",
    "#                 retrieved_contents[0],\n",
    "#                 cleanup,\n",
    "#             ),\n",
    "#             delta_threshold=0.1\n",
    "#         )\n",
    "#         score = score_partition(tp, output_tokens)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     display(score)\n",
    "#     if score == 1:\n",
    "#         return tokens\n",
    "#     else:\n",
    "#         return max(score, divide_and_conquer())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_sentences_in = [\"Senex is a Latin word literally meaning a man of old age.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve_mode = \"top_k\"\n",
    "\n",
    "# # Get table with token similarities for each \"out-of-train\" sentence.\n",
    "# retrieved_contents = inference.infer(\n",
    "#     memory.address_size,\n",
    "#     cleanup,\n",
    "#     memory,\n",
    "#     inference_sentences_in,\n",
    "#     retrieve_mode=retrieve_mode,\n",
    "#     k=3, #TODO: What if index is out of range?\n",
    "# )\n",
    "\n",
    "# if retrieve_mode == \"top_k\":\n",
    "#     sims_df = pd.DataFrame(columns=['sentence', 'token', 'similarity']) \n",
    "    \n",
    "#     for s, addresses in zip(inference_sentences_in, retrieved_contents):\n",
    "#         display(s)\n",
    "#         for a in addresses:\n",
    "#             address_sims_df = inference.get_similarities_to_atomic_set(\n",
    "#                 a, cleanup)\n",
    "#             display(address_sims_df)\n",
    "# elif retrieve_mode == \"pooling\":  \n",
    "#     sims_df = pd.DataFrame(columns=['sentence', 'token', 'similarity']) \n",
    "      \n",
    "#     for s, c in zip(inference_sentences_in, retrieved_contents):\n",
    "#         sentence_sims_df = inference.get_similarities_to_atomic_set(\n",
    "#             c, cleanup)\n",
    "#         sentence_sims_df['sentence'] = [s] * len(sentence_sims_df)\n",
    "#         sims_df = pd.concat([sims_df, sentence_sims_df])\n",
    "\n",
    "#     sims_df = sims_df.sort_values(['sentence', 'similarity'], ascending=False) \\\n",
    "#                      .set_index(['sentence', 'token'])\n",
    "    \n",
    "#     display(sims_df)\n",
    "# else:  # unrecognized\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics address space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Address 244"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyrenula</td>\n",
       "      <td>0.373351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creek</td>\n",
       "      <td>0.289624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–</td>\n",
       "      <td>0.288052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mills</td>\n",
       "      <td>0.189147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>born</td>\n",
       "      <td>0.176940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>0.173557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nescopeck</td>\n",
       "      <td>0.170269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>american</td>\n",
       "      <td>0.143547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>two</td>\n",
       "      <td>0.142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>university</td>\n",
       "      <td>0.130298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  similarity\n",
       "0    pyrenula    0.373351\n",
       "1       creek    0.289624\n",
       "2           –    0.288052\n",
       "3       mills    0.189147\n",
       "4        born    0.176940\n",
       "5         new    0.173557\n",
       "6   nescopeck    0.170269\n",
       "7    american    0.143547\n",
       "8         two    0.142125\n",
       "9  university    0.130298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 245"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyrenula</td>\n",
       "      <td>0.368364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creek</td>\n",
       "      <td>0.295643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–</td>\n",
       "      <td>0.291094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mills</td>\n",
       "      <td>0.188769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>born</td>\n",
       "      <td>0.180576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nescopeck</td>\n",
       "      <td>0.173325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new</td>\n",
       "      <td>0.172754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>american</td>\n",
       "      <td>0.142314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>two</td>\n",
       "      <td>0.137888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>watershed</td>\n",
       "      <td>0.135716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  similarity\n",
       "0   pyrenula    0.368364\n",
       "1      creek    0.295643\n",
       "2          –    0.291094\n",
       "3      mills    0.188769\n",
       "4       born    0.180576\n",
       "5  nescopeck    0.173325\n",
       "6        new    0.172754\n",
       "7   american    0.142314\n",
       "8        two    0.137888\n",
       "9  watershed    0.135716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 246"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyrenula</td>\n",
       "      <td>0.371117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–</td>\n",
       "      <td>0.292351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creek</td>\n",
       "      <td>0.291638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mills</td>\n",
       "      <td>0.190354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>born</td>\n",
       "      <td>0.179786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>0.176420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nescopeck</td>\n",
       "      <td>0.173126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>american</td>\n",
       "      <td>0.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>two</td>\n",
       "      <td>0.138602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>university</td>\n",
       "      <td>0.131640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  similarity\n",
       "0    pyrenula    0.371117\n",
       "1           –    0.292351\n",
       "2       creek    0.291638\n",
       "3       mills    0.190354\n",
       "4        born    0.179786\n",
       "5         new    0.176420\n",
       "6   nescopeck    0.173126\n",
       "7    american    0.141062\n",
       "8         two    0.138602\n",
       "9  university    0.131640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 247"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyrenula</td>\n",
       "      <td>0.370287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–</td>\n",
       "      <td>0.299116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creek</td>\n",
       "      <td>0.295333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mills</td>\n",
       "      <td>0.185233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>0.173719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nescopeck</td>\n",
       "      <td>0.172965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>born</td>\n",
       "      <td>0.171152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>american</td>\n",
       "      <td>0.142391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>two</td>\n",
       "      <td>0.138714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>watershed</td>\n",
       "      <td>0.134785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  similarity\n",
       "0   pyrenula    0.370287\n",
       "1          –    0.299116\n",
       "2      creek    0.295333\n",
       "3      mills    0.185233\n",
       "4        new    0.173719\n",
       "5  nescopeck    0.172965\n",
       "6       born    0.171152\n",
       "7   american    0.142391\n",
       "8        two    0.138714\n",
       "9  watershed    0.134785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#addresses = np.random.randint(0, len(memory.addresses), size=30)\n",
    "addresses = [244, 245, 246, 247]\n",
    "#addresses = [56, 55, 54, 53, 52, 51]\n",
    "for address in addresses:\n",
    "    display(md(f\"### Address {address}\"))\n",
    "    address_sims_df = inference.get_similarities_to_atomic_set(\n",
    "            memory.addresses[address],\n",
    "            cleanup,\n",
    "    )\n",
    "    display(address_sims_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6107950104730047"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.n_updates / (memory.n_updates + memory.n_expansions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39075"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.n_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24899"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.n_expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24899"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory.addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.n_deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
