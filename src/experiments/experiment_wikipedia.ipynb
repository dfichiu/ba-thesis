{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window n-gram method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the training of a DSDM instance (located in folder [src/lib/memory/DSDM.py](https://github.com/dfichiu/ba-thesis/blob/master/src/lib/memory/DSDM.py)) using the sliding window n-gram method.\n",
    "\n",
    "\n",
    "The experiment currently run is the one presented in the 'Experiments' section of the thesis, i.e., training on a small piece of text (w/o stop words) taken from a Guardian article to check whether distance-aware representations get constructed. To track the values of the EMA threshold and the minimum cosine distance (to-BMU distance), please uncomment the respective lines in the `save` method of the [DSDM class](https://github.com/dfichiu/ba-thesis/blob/master/src/lib/memory/DSDM.py).\n",
    "\n",
    "For longer training sessions, please use the training script [src/experiments/train_SWNmemory.py](https://github.com/dfichiu/ba-thesis/blob/master/src/experiments/train_SWNmemory.py).\n",
    "\n",
    "<ins> Note</ins> (Preprocessing): The sliding window n-gram method was developed before the method mining Transformer self-attention. Initially, we used a preprocessing pipeline based on sklearn's Pipeline module. (See [preprocessing](https://github.com/dfichiu/ba-thesis/blob/master/src/lib/utils/preprocess.py).) Therefore, to remove or keep stopwords, we commented the respective step in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory.\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path to be able to import modules from 'lib.'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dGeeI-H3NGMx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /nfs/home/dfichiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /nfs/home/dfichiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /nfs/home/dfichiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "from IPython.display import HTML, Markdown as md\n",
    "import itertools\n",
    "\n",
    "from lib.memory import DSDM\n",
    "from lib.utils import cleanup, configs, inference, learning, preprocess, utils \n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchhd as thd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "# Type checking\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/nfs/data/projects/daniela/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Wikipedia dataset.\n",
    "# TODO: Split between server and local.\n",
    "#wiki_dataset = datasets.load_dataset(\"wikipedia\", \"20220301.en\")['train']\n",
    "wiki_dataset = datasets.load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.en\",\n",
    "    cache_dir=\"/nfs/data/projects/daniela\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Using seed: 41"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seed.\n",
    "utils.fix_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6iuLthXgNKLP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set DSDM hyperparameters.\n",
    "address_size = 1000\n",
    "\n",
    "ema_time_period = 50\n",
    "learning_rate_update = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "normalize = False\n",
    "\n",
    "# Pruning\n",
    "prune_mode = None\n",
    "max_size_address_space = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram size\n",
    "chunk_sizes = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize codebook, i.e., class that saves token - atomic hypervector associations.\n",
    "cleanup = cleanup.Cleanup(address_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory.\n",
    "memory = DSDM.DSDM(\n",
    "    address_size=address_size,\n",
    "    ema_time_period=ema_time_period,\n",
    "    learning_rate_update=learning_rate_update,\n",
    "    temperature=temperature,\n",
    "    normalize=normalize,\n",
    "    prune_mode=prune_mode,\n",
    "    max_size_address_space=max_size_address_space\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct train set (texts) and inference set (sentences; in and out of train set text).\n",
    "train_size = 1\n",
    "\n",
    "train_size = 10 # Parameter: Number of train articles\n",
    "\n",
    "train_idx = np.random.randint(0, len(wiki_dataset) - 1000, size=1000000)\n",
    "# Select train articles.\n",
    "train_idx = train_idx[:train_size]\n",
    "# Manually add the articles from which the in-set inference sentences were selected.\n",
    "train_idx = np.append(np.array([6458629, 6458633, 6458645, 6458648, 6458659, 6458664, 6458665,\n",
    "   6458667, 6458668, 6458573]), train_idx)\n",
    "\n",
    "# # Text indeces\n",
    "# train_idx = np.random.randint(0, len(wiki_dataset) - 100, size=train_size)\n",
    "# # Generate and append train articles present in all experiments.\n",
    "# intest_idx = np.random.randint(len(wiki_dataset) - 100, len(wiki_dataset), size=20)\n",
    "# _set = list(set(intest_idx))\n",
    "# intest_idx = np.array(_set)[: len(_set) // 2]\n",
    "# outtest_idx = np.array(_set)[len(_set) // 2 :]\n",
    "# train_idx = np.append(train_idx, intest_idx)\n",
    "\n",
    "# Text indeces from which we extract sentences.\n",
    "# intest_idx = np.random.choice(train_idx, test_size)\n",
    "# outtest_idx = np.random.choice(np.setdiff1d(np.arange(len(wiki_dataset)), train_idx), test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_sentences_in = []\n",
    "# inference_sentences_out = []\n",
    "\n",
    "# for idx_in, idx_out in zip(intest_idx, outtest_idx):\n",
    "#     # Get sentences.\n",
    "#     sentences_in = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_in)]['text'])\n",
    "#     sentences_out = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_out)]['text'])\n",
    "    \n",
    "#     # Get sentence index.\n",
    "#     sentence_idx_in = int(\n",
    "#         np.random.randint(\n",
    "#             0,\n",
    "#             len(sentences_in),\n",
    "#             size=1\n",
    "#         ).item()\n",
    "#     )\n",
    "#     sentence_idx_out = int(\n",
    "#         np.random.randint(\n",
    "#             0,\n",
    "#             len(sentences_out),\n",
    "#             size=1\n",
    "#         ).item()\n",
    "#     )\n",
    "\n",
    "#     # Append sentence to list.\n",
    "#     inference_sentences_in.append(sentences_in[sentence_idx_in])\n",
    "#     inference_sentences_out.append(sentences_out[sentence_idx_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "remove_dups = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove duplicates ###\n",
    "dups_found = 0\n",
    "\n",
    "def remove_duplicates(memory):\n",
    "    \"\"\"Remove duplicate addresses from a DSDM object.\n",
    "    \n",
    "    Given a DSDM object, for each address, remove address that have a (cosine) similarity\n",
    "    higer than 0.95 to it.\n",
    "    \n",
    "    Implemented by a global keep mask that is updated for each address using 'and.'\n",
    "    \"\"\"\n",
    "    \n",
    "    global dups_found\n",
    "    global_keep_mask = torch.tensor([True] * len(memory.addresses)).to(device)\n",
    "    \n",
    "    for idx, address in enumerate(memory.addresses):\n",
    "        if global_keep_mask[idx].item():\n",
    "            cos = torch.nn.CosineSimilarity()\n",
    "            keep_mask = cos(memory.addresses, address) < 0.8\n",
    "            # Keep current address\n",
    "            keep_mask[idx] = True\n",
    "            global_keep_mask &= keep_mask\n",
    "\n",
    "    if global_keep_mask.sum().item() > 0:\n",
    "        dups_found += len(global_keep_mask) - global_keep_mask.sum().item()\n",
    "        # Remove similar addresses\n",
    "        memory.addresses = memory.addresses[global_keep_mask]\n",
    "        # Remove bins & chunk scores\n",
    "        memory.scores = memory.scores[global_keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "### Training ###\n",
    "for i in tqdm(train_idx):\n",
    "    text = wiki_dataset[int(i)]['text']\n",
    "    \n",
    "    # Piece of text extracted from a Guardian article.\n",
    "    text = \"\"\"\n",
    "    Images showed widespread destruction across Marrakech, a Unesco world heritage site where newer apartment complexes on the edge of the sprawling city border a network of alleyways shaded by historic and ornate buildings.\n",
    "    The earthquake, its magnitude estimated at 6.8, sent stone slabs tumbling to the ground, creating piles of rubble in the streets as terrified people fled and spent the night on the pavement and in squares, afraid to return to their homes.\n",
    "    As Saturday dawned, Shonibare described how people rushed to check on their neighbours amid confusion and fear about whether to remain outdoors or shelter from potential aftershocks and the soaring early September temperatures.\n",
    "    It’s hard to get a sense of how things are being managed. So far we have been seeing police vans, ambulances and fire trucks going to the centre. It seems they are doing the best they can but I do not know if anyone fully knows the extent of the damage their neighbours amid confusion and fear about whether to remain outdoors.\"\"\"\n",
    "    \n",
    "    # Preprocess data. \n",
    "    sentences_tokens = preprocess.preprocess_text(text)\n",
    "    for sentence_tokens in sentences_tokens:\n",
    "        # Generate atomic HVs for unknown tokens.\n",
    "        learning.generate_atomic_HVs_from_tokens_and_add_them_to_cleanup(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            sentence_tokens\n",
    "        )\n",
    "        \n",
    "        # Learning: Construct the chunks of each sentence and save them to memory.\n",
    "        learning.generate_chunk_representations_and_save_them_to_memory(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            memory,\n",
    "            sentence_tokens,\n",
    "            chunk_sizes=chunk_sizes\n",
    "        )\n",
    "    if remove_dups:\n",
    "        remove_duplicates(memory)\n",
    "    # Break in order to train only the piece of text.\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_sentences_in = ['Dagored', 'is an Italian', 'record labels', 'based in Firenze', 'formed', 'in 1998.'] 250, 0.05 temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Old idea: Divide and conquer to improve inference. ###\n",
    "# def score_partition(input_partition, output_partition):\n",
    "#     # Note: What if a sentence contains the same word multiple times? This is why using 'set' is a bad idea!\n",
    "#     set_query = set(preprocess.remove_stopwords(tokens)[0]) \n",
    "#     set_content = inference.get_most_similar_HVs(sentence_sims_df, delta_threshold=0.1)\n",
    "\n",
    "#     set_input = set(input_partition)\n",
    "#     set_output = set(output_partition)\n",
    "    \n",
    "#     score = len(set_input.intersection(set_output)) / len(set_input)\n",
    "#     return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def divide_and_conquer(token_partitions: typing.List[typing.List[str]]):\n",
    "#     retrieve_mode = \"pooling\"\n",
    "    \n",
    "#     for tp in token_partitions:\n",
    "#         retrieved_content = inference.infer(\n",
    "#             memory.address_size,\n",
    "#             cleanup,\n",
    "#             memory,\n",
    "#             [tp],\n",
    "#             retrieve_mode=retrieve_mode\n",
    "#         )\n",
    "#         output_tokens = inference.get_most_similar_HVs(\n",
    "#             inference.get_similarities_to_atomic_set(\n",
    "#                 retrieved_contents[0],\n",
    "#                 cleanup,\n",
    "#             ),\n",
    "#             delta_threshold=0.1\n",
    "#         )\n",
    "#         score = score_partition(tp, output_tokens)\n",
    "\n",
    "#     display(score)\n",
    "#     if score == 1:\n",
    "#         return tokens\n",
    "#     else:\n",
    "#         return max(score, divide_and_conquer())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve_mode = \"top_k\"\n",
    "\n",
    "# # Get table with token similarities for each \"out-of-train\" sentence.\n",
    "# retrieved_contents = inference.infer(\n",
    "#     memory.address_size,\n",
    "#     cleanup,\n",
    "#     memory,\n",
    "#     inference_sentences_in,\n",
    "#     retrieve_mode=retrieve_mode,\n",
    "#     k=3, #TODO: What if index is out of range?\n",
    "# )\n",
    "\n",
    "# if retrieve_mode == \"top_k\":\n",
    "#     sims_df = pd.DataFrame(columns=['sentence', 'token', 'similarity']) \n",
    "    \n",
    "#     for s, addresses in zip(inference_sentences_in, retrieved_contents):\n",
    "#         display(s)\n",
    "#         for a in addresses:\n",
    "#             address_sims_df = inference.get_similarities_to_atomic_set(\n",
    "#                 a, cleanup)\n",
    "#             display(address_sims_df)\n",
    "# elif retrieve_mode == \"pooling\":  \n",
    "#     sims_df = pd.DataFrame(columns=['sentence', 'token', 'similarity']) \n",
    "      \n",
    "#     for s, c in zip(inference_sentences_in, retrieved_contents):\n",
    "#         sentence_sims_df = inference.get_similarities_to_atomic_set(\n",
    "#             c, cleanup)\n",
    "#         sentence_sims_df['sentence'] = [s] * len(sentence_sims_df)\n",
    "#         sims_df = pd.concat([sims_df, sentence_sims_df])\n",
    "\n",
    "#     sims_df = sims_df.sort_values(['sentence', 'similarity'], ascending=False) \\\n",
    "#                      .set_index(['sentence', 'token'])\n",
    "    \n",
    "#     display(sims_df)\n",
    "# else:  # unrecognized\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Address 56"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extent</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>damage</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neighbours</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amid</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>confusion</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>knows</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fully</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rubble</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>return</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  similarity\n",
       "0      extent        0.49\n",
       "1      damage        0.48\n",
       "2  neighbours        0.46\n",
       "3        amid        0.36\n",
       "4   confusion        0.27\n",
       "5       knows        0.24\n",
       "6       fully        0.19\n",
       "7  earthquake        0.08\n",
       "8      rubble        0.07\n",
       "9      return        0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 55"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fully</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyone</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knows</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extent</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>know</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>damage</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>best</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shonibare</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ornate</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shelter</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  similarity\n",
       "0      fully        0.51\n",
       "1     anyone        0.50\n",
       "2      knows        0.47\n",
       "3     extent        0.42\n",
       "4       know        0.27\n",
       "5     damage        0.24\n",
       "6       best        0.18\n",
       "7  shonibare        0.07\n",
       "8     ornate        0.06\n",
       "9    shelter        0.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 54"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambulances</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trucks</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fire</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>going</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>centre</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vans</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>police</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>return</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dawned</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>city</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  similarity\n",
       "0  ambulances        0.53\n",
       "1      trucks        0.50\n",
       "2        fire        0.47\n",
       "3       going        0.38\n",
       "4      centre        0.28\n",
       "5        vans        0.28\n",
       "6      police        0.13\n",
       "7      return        0.10\n",
       "8      dawned        0.10\n",
       "9        city        0.09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 53"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vans</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambulances</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>police</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seeing</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>far</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fire</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>return</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buildings</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dawned</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soaring</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  similarity\n",
       "0        vans        0.50\n",
       "1  ambulances        0.48\n",
       "2      police        0.48\n",
       "3      seeing        0.48\n",
       "4         far        0.27\n",
       "5        fire        0.22\n",
       "6      return        0.09\n",
       "7   buildings        0.06\n",
       "8      dawned        0.06\n",
       "9     soaring        0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 52"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>things</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sense</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>managed</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>’</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ornate</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>magnitude</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>centre</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>piles</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  similarity\n",
       "0        get        0.52\n",
       "1     things        0.47\n",
       "2       hard        0.44\n",
       "3      sense        0.44\n",
       "4    managed        0.25\n",
       "5          ’        0.21\n",
       "6     ornate        0.07\n",
       "7  magnitude        0.06\n",
       "8     centre        0.06\n",
       "9      piles        0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Address 51"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aftershocks</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>early</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>september</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temperatures</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soaring</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whether</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>managed</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rushed</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ground</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  similarity\n",
       "0   aftershocks        0.47\n",
       "1         early        0.45\n",
       "2     september        0.45\n",
       "3  temperatures        0.43\n",
       "4       soaring        0.43\n",
       "5       whether        0.08\n",
       "6       managed        0.07\n",
       "7        rushed        0.06\n",
       "8        ground        0.05\n",
       "9          know        0.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# addresses = np.random.randint(0, len(memory.addresses), size=30)\n",
    "# addresses = [244, 245, 246, 247]\n",
    "addresses = [56, 55, 54, 53, 52, 51]\n",
    "for address in addresses:\n",
    "    display(md(f\"### Address {address}\"))\n",
    "    address_sims_df = inference.get_similarities_to_atomic_set(\n",
    "            memory.addresses[address],\n",
    "            cleanup,\n",
    "    )\n",
    "    display(address_sims_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updates percentage: 0.23%\n"
     ]
    }
   ],
   "source": [
    "print (f\"Updates percentage: {round(memory.n_updates / (memory.n_updates + memory.n_expansions), 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of memory updates: 17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of memory updates: {memory.n_updates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of memory expansions: 57\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of memory expansions: {memory.n_expansions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing memory addresses: 57\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of existing memory addresses: {len(memory.addresses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.n_deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_found"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
