{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the parent directory.\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path to be able to import modules from 'lib.'\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dGeeI-H3NGMx"
   },
   "outputs": [],
   "source": [
    "import datasets #import load_dataset\n",
    "\n",
    "from IPython.display import HTML, Markdown as md\n",
    "import itertools\n",
    "\n",
    "from lib.memory import DSDM\n",
    "from lib.utils import configs, inference, learning, preprocess, utils \n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchhd as thd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "from tqdm import tqdm\n",
    "# Type checking\n",
    "from typing import List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/Users/danielastelea/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b8ba25674c4cd193db82d6c8c9ae16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Wikipedia dataset.\n",
    "wiki_dataset = datasets.load_dataset(\"wikipedia\", \"20220301.en\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Using seed: 41"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set seed.\n",
    "utils.fix_seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = {} # Cleanup memory for saving atomic HVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6iuLthXgNKLP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set DSDM hyperparameters.\n",
    "address_size = 1000\n",
    "ema_time_period = 5000\n",
    "learning_rate_update = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "normalize = False\n",
    "\n",
    "chunk_sizes = [5]\n",
    "\n",
    "prune_mode = \"fixed-size\"\n",
    "max_size_address_space = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory.\n",
    "memory = DSDM.DSDM(\n",
    "    address_size=address_size,\n",
    "    ema_time_period=ema_time_period,\n",
    "    learning_rate_update=learning_rate_update,\n",
    "    temperature=temperature,\n",
    "    normalize=normalize,\n",
    "    prune_mode=prune_mode,\n",
    "    max_size_address_space=max_size_address_space\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct train set (texts) and inference set (sentences; in and out of train set text).\n",
    "train_size = 1\n",
    "test_size = 1\n",
    "\n",
    "# Text indeces.\n",
    "train_idx = np.random.randint(0, len(wiki_dataset), size=train_size)\n",
    "\n",
    "# Caclulate chosen text statistics.\n",
    "# TODO\n",
    "\n",
    "# Text indeces from which we extract sentences.\n",
    "intest_idx = np.random.choice(train_idx, test_size)\n",
    "outtest_idx = np.random.choice(np.setdiff1d(np.arange(len(wiki_dataset)), train_idx), test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sentences_in = []\n",
    "inference_sentences_out = []\n",
    "\n",
    "for idx_in, idx_out in zip(intest_idx, outtest_idx):\n",
    "    # Get sentences.\n",
    "    sentences_in = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_in)]['text'])\n",
    "    sentences_out = utils.preprocess.split_text_into_sentences(wiki_dataset[int(idx_out)]['text'])\n",
    "    \n",
    "    # Get sentence index.\n",
    "    sentence_idx_in = int(\n",
    "        np.random.randint(\n",
    "            0,\n",
    "            len(sentences_in),\n",
    "            size=1\n",
    "        ))\n",
    "    sentence_idx_out = int(\n",
    "        np.random.randint(\n",
    "            0,\n",
    "            len(sentences_out),\n",
    "            size=1\n",
    "        ))\n",
    "\n",
    "    # Append sentence to list.\n",
    "    inference_sentences_in.append(sentences_in[sentence_idx_in])\n",
    "    inference_sentences_out.append(sentences_out[sentence_idx_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in tqdm(train_idx):\n",
    "    text = wiki_dataset[int(i)]['text']\n",
    "    \n",
    "    # Preprocess data. \n",
    "    sentences_tokens = preprocess.preprocess_text(text)\n",
    "    \n",
    "    for sentence_tokens in sentences_tokens:\n",
    "        # Generate atomic HVs for unknown tokens.\n",
    "        learning.generate_atomic_HVs_from_tokens_and_add_them_to_cleanup(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            sentence_tokens\n",
    "        )\n",
    "        \n",
    "        # Learning: Construct the chunks of each sentence and save them to memory.\n",
    "        learning.generate_chunk_representations_and_save_them_to_memory(\n",
    "            memory.address_size,\n",
    "            cleanup,\n",
    "            memory,\n",
    "            sentence_tokens,\n",
    "            chunk_sizes=chunk_sizes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get table with token similarities for each \"in-train\" sentence.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m in_sims_df \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_sentences_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrieve_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m display(in_sims_df)\n",
      "File \u001b[0;32m~/Desktop/Uni/Bachelor/Heidelberg/22-23/WS22-23/InfoBachelorarbeit/ba-thesis/src/lib/utils/inference.py:214\u001b[0m, in \u001b[0;36minfer\u001b[0;34m(dim, cleanup, memory, inference_sentences, retrieve_mode, k, output)\u001b[0m\n\u001b[1;32m    211\u001b[0m addresses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inference_sentence \u001b[38;5;129;01min\u001b[39;00m inference_sentences:\n\u001b[0;32m--> 214\u001b[0m     sentence_addresses \u001b[38;5;241m=\u001b[39m \u001b[43mget_similarities_to_atomic_HVs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_sentence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretrieve_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     addresses\u001b[38;5;241m.\u001b[39mappend(sentence_addresses)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m addresses\n",
      "File \u001b[0;32m~/Desktop/Uni/Bachelor/Heidelberg/22-23/WS22-23/InfoBachelorarbeit/ba-thesis/src/lib/utils/inference.py:69\u001b[0m, in \u001b[0;36mget_similarities_to_atomic_HVs\u001b[0;34m(dim, cleanup, memory, sentence, retrieve_mode, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_similarities_to_atomic_HVs\u001b[39m(\n\u001b[1;32m     60\u001b[0m     dim: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     61\u001b[0m     cleanup: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Actual inteference \u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     retrieved_content \u001b[38;5;241m=\u001b[39m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretrieve_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrieve_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retrieve_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     80\u001b[0m         sims_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     81\u001b[0m             columns\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     82\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m             ]\n\u001b[1;32m     86\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/Uni/Bachelor/Heidelberg/22-23/WS22-23/InfoBachelorarbeit/ba-thesis/src/lib/memory/DSDM.py:117\u001b[0m, in \u001b[0;36mDSDM.retrieve\u001b[0;34m(self, query_address, retrieve_mode, k)\u001b[0m\n\u001b[1;32m    110\u001b[0m val, idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(\n\u001b[1;32m    111\u001b[0m     softmin_weights\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    112\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    113\u001b[0m     largest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx:\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mreturn_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddresses[return_mask]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ba-thesis-YAFM42rh-py3.9/lib/python3.9/site-packages/torch/_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# Get table with token similarities for each \"in-train\" sentence.\n",
    "in_sims_df = inference.infer(\n",
    "    memory.address_size,\n",
    "    cleanup,\n",
    "    memory,\n",
    "    inference_sentences_in,\n",
    "    retrieve_mode=\"top_k\",\n",
    "    k=5,\n",
    ")\n",
    "display(in_sims_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table with token similarities for each \"out-of-train\" sentence.\n",
    "out_sims_df = inference.infer(\n",
    "    memory.address_size,\n",
    "    cleanup,\n",
    "    memory,\n",
    "    inference_sentences_out,\n",
    "    retrieve_mode=\"top_k\",\n",
    "    k=5,\n",
    ")\n",
    "display(out_sims_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_df = inference.infer(\n",
    "    memory.address_size,\n",
    "    cleanup,\n",
    "    memory,\n",
    "    ['The index was created in the early 1960s to limit the sale of such works to minors due to their chauvinism and glorification of violence.']\n",
    ")\n",
    "display(sims_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = np.random.randint(0, len(memory.addresses), size=10)\n",
    "\n",
    "for address in addresses:\n",
    "    display(md(f\"### Address {address}\"))\n",
    "    retrieved_content = memory.addresses[address]\n",
    "    \n",
    "    memory_sims_df = pd.DataFrame(columns=['token', 'similarity'])\n",
    "    \n",
    "    for token, atomic_HC in cleanup.items():\n",
    "        memory_sims_df = pd.concat([memory_sims_df, pd.DataFrame([{'token': token,\n",
    "                                                                   'similarity': thd.cosine_similarity(atomic_HC, retrieved_content).item()}])])\n",
    "    memory_sims_df = memory_sims_df.sort_values('similarity', ascending=False).reset_index(drop=True)\n",
    "    display(memory_sims_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.n_updates / (memory.n_updates + memory.n_expansions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.n_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.n_expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory.addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1, 2, 3, 4])[[False, True, True, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
